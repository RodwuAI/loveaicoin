## 第10章：Token管理——从管人到管算力

### 传统企业管人 vs 智能体公司管Token

先来一个类比，帮你建立直觉：

| 传统公司（管人） | 智能体公司（管Token） ||---|---|
| 工资是最大开支 | API费用是最大开支 |
| HR负责招聘和管理 | Main Agent负责调度和管理 |
| 月底发工资 | 实时扣Token |
| 绩效考核决定奖金 | 输出质量决定是否换模型 |
| 员工请假=产能下降 | API宕机=产能下降 |
| 培训提升能力 | 升级模型提升能力 |
| 裁员=降低成本 | 降级模型=降低成本 |
| 办公室租金固定 | 服务器费用弹性 |

核心区别在于：**人力成本是刚性的**（不开张也要发工资），**Token成本是弹性的**（不干活就不花钱）。这是智能体公司最大的结构性优势。

### Token成本分层模型

不同的任务，应该用不同"价位"的模型：

| 任务类型 | 推荐模型 | 单次成本 | 适用场景 |
|----------|----------|----------|----------|
| 战略决策 | Claude Opus | $0.15-0.75/次 | 方案制定、复杂推理、验收审核 |
| 内容生产 | Kimi K2.5 / DeepSeek V3 | $0.01-0.05/次 | 文案、翻译、整理、报告 |
| 代码生成 | Sonnet / Kimi Coding | $0.03-0.10/次 | 编程、调试、代码审查 |
| 数据分析 | DeepSeek R1 | $0.02-0.08/次 | 推理链分析、逻辑验证 |
| 多模态任务 | Gemini 3 Pro | $0.01-0.05/次 | 图片生成、视觉分析 |
| 快速查询 | Gemini Flash | $0.001-0.01/次 | 搜索、简单问答 |

**原则：能用便宜模型解决的，绝不用贵的。** 就像传统公司不会让总监去做前台的活。

### Token管理三级预警

1. **🟢 绿色（<60%预算）：** 正常运行，无限制
2. **🟡 黄色（60-85%预算）：** 自动降级——Opus任务转Sonnet，非紧急任务排队
3. **🔴 红色（>85%预算）：** 紧急——只保留Main Agent和关键Agent，其余暂停

### Token节省实战技巧（10条）

1. **Prompt缓存** — 重复的系统提示只传一次，后续调用自动复用，省30-50%
2. **分层调用** — 简单任务用便宜模型，复杂任务才上贵的
3. **批量处理** — 把10个小任务合成1个大Prompt，减少API调用开销
4. **上下文压缩** — 定期清理对话历史，只保留关键上下文
5. **输出长度控制** — 在Prompt中明确要求"用200字以内回答"，避免AI长篇大论
6. **模型降级策略** — 初稿用便宜模型，终稿才用贵模型打磨
7. **Few-shot vs Zero-shot** — 给1-2个示例比长篇描述更省Token且效果更好
8. **定时清理会话** — 长对话会累积大量上下文，定期开新会话
9. **复用模板** — 把常用Prompt做成模板，每次只改变量部分
10. **监控异常消耗** — 设置每日预算上限，异常消耗立即告警

> 🔥 **实战案例（LAC）| 2026-02-20：Gemini 503全线宕机**
>
> 凌晨5点，我们7份文档在同步推进。突然，3个使用Gemini 3 Pro的Agent全部返回503错误——链鹰（Web3分析师）、设计师、财奴（商业化），全军覆没。
>
> 原因：Gemini的语音转录服务过载，影响了整个API集群的稳定性。我们的Agent虽然没有用语音功能，但也被波及。
>
> 蜂王（小嘀嗒）在30秒内做出决策：把3个Gemini任务全部转给经济师Agent（Opus模型），作为万能代班。代价是成本上升了约3倍，但生产线零停机。
>
> 凌晨6点17分，7份文档全部完成初稿。如果没有备用方案，我们至少要停工4小时等Gemini恢复。
>
> **教训：永远为核心Agent准备一个不同供应商的备用模型。单一供应商依赖是最大的风险。**

---
